#include "config.h"


#ifndef typedefinitions_h
#define typedefinitions_h

typedef char CHAR;                   // Signed 8 bits
typedef unsigned char UCHAR;         // Unsigned 8 bits
typedef short SHORT;                 // Signed 16 bits
typedef unsigned short USHORT;       // Unsigned 16 bits
typedef long LONG;                   // Signed 64 bit
typedef unsigned long ULONG;         // unsigned 64 bit
typedef int SINT;                    // signed 32 bit
typedef unsigned int UINT;           // unsigned 32 bit

typedef bool BOOL;                   // BOOLEAN VALUE!!!!

typedef long s64;
typedef int s32;
typedef unsigned int u32;
typedef short s16;
typedef signed char  s8;

typedef const long sc64;            // Read Only
typedef const int sc32;             // Read Only
typedef const unsigned int uc32;    // Read Only
typedef const short sc16;           // Read Only
typedef const char sc8;             // Read Only

typedef ULONG  u64;                 // Read Only
typedef USHORT u16;                 // Read Only
typedef UCHAR  u8;                  // Read Only

typedef const ULONG uc64;           // Read Only
typedef const USHORT uc16;          // Read Only
typedef const UCHAR uc8;            // Read Only

// These are not strictly necessary but might be useful
typedef enum {RESET = 0, SET = !RESET} FlagStatus, ITStatus;
typedef enum {DISABLE = 0, ENABLE = !DISABLE} FunctionalState;
typedef enum {ERROR = 0, SUCCESS = !ERROR} ErrorStatus;

typedef struct
{
  int nBytes;
  float prob1s;
  int argc;
  char** argv;
} stateVariables;

stateVariables determineSequence(stateVariables stateVars);

void printBits(int nBytes, void const * const ptr);//
/*
REQUIRES:
ASSUMES LITTLE ENDIAN

ptr: pointer to bytes being turned into bits.
nBytes: number of bytes being written

PRODUCES:
a printed BIT stream.
*/

u8* pu8GenRdmAsciiByteStream (int nBytes);
/*
REQUIRES:
nBytes: number of bytes being generated

PRODUCES:
A random ASCII byte stream with length number of bytes nBytes
The method here is slightly different than used in pu8GenBiasedRdmBitStream. rand()%26 +'a' is used to create a ascii character. Further analysis of the differences to be analyzed. 
*/
void writeToFile(uc8* puc8inputBytes, int nBytes);
/*
REQUIRES:
puc8inputBytes: pointer to bytes being written
nBytes: number of bytes being written

PRODUCES:
A binary file with the generated bytes written
*/


u8* readFromFile(int nBytes);
/*
REQUIRES:
nBytes: number of bytes being read

PRODUCES:
A byte pointer containing the contents of a binary file
*/
u8* pu8GenBiasedRdmBitStream (int nBytes, float p);
/*
REQUIRES:
p: probability of 1's in bitstream
nBytes: number of bytes being generated

PRODUCES:
A random bit stream with length number of bytes and the probability of 1's as p. This is done by generating a random variate with uniform distribution from [0,1) and checking if p is less than this value and assigning the generated bit accordingly. NOTE, some of the limitations of using this are well outlined by:
https://codereview.stackexchange.com/questions/159604/uniform-random-numbers-in-an-integer-interval-in-c

This creates some interesting results. There appear to be lots of bits in a row that are the same. This may because of the calls to srand. VISUALLY (not empirically/statiscally) the method in pu8GenRdmAsciiByteStream appears to give more uniform results.
*/
#endif                              // typedefinitions.h
